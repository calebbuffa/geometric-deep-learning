{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "from typing import Callable, Sequence\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "import laspy as lp\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URLS = (\n",
    "    \"https://github.com/calebbuffa/geometric-deep-learning/raw/main/data/test.laz\",\n",
    "    \"https://github.com/calebbuffa/geometric-deep-learning/raw/main/data/train.laz\"\n",
    ")\n",
    "\n",
    "DATA_URLS_WITH_GEOM = (\n",
    "    \"https://github.com/calebbuffa/geometric-deep-learning/raw/main/data/test_with_geom.laz\",\n",
    "    \"https://github.com/calebbuffa/geometric-deep-learning/raw/main/data/train_with_geom.laz\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rotate(x: torch.Tensor):\n",
    "    theta = torch.pi * 2 * torch.rand(1)\n",
    "    rotation_matrix = torch.tensor(\n",
    "        [\n",
    "            [\n",
    "                torch.cos(theta),\n",
    "                -torch.sin(theta)\n",
    "            ],\n",
    "             [\n",
    "                  torch.sin(theta),\n",
    "                  torch.cos(theta)\n",
    "            ]\n",
    "        ],\n",
    "        dtype=x.dtype\n",
    "    )\n",
    "    x[..., [0, 1]] = x[..., [0, 1]] @ (rotation_matrix)\n",
    "    x[..., [6, 7]] = x[..., [6, 7]] @ (rotation_matrix)\n",
    "    return x\n",
    "\n",
    "def center(x: np.ndarray, dim: int = 0):\n",
    "    \"\"\"\n",
    "    Center input to 0 mean.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor\n",
    "        Input to center.\n",
    "    dim : int\n",
    "        Dimension to extract mean, defaults to 0.\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "    \"\"\"\n",
    "    return x - x.mean(axis=dim, keepdims=True)\n",
    "\n",
    "\n",
    "def scale(\n",
    "    x: np.ndarray,\n",
    "    new_range: tuple[int, int] = (-1, 1),\n",
    "    eps: float = 1e-20,\n",
    "    dim: int = 0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Scale input features to new min/max.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor\n",
    "        Features to scale.\n",
    "    new_range : tuple[int, int]\n",
    "        New min/max range, defaults to (-1, 1).\n",
    "    eps : float\n",
    "        Value to avoid division by zero.\n",
    "    dim : int\n",
    "        Dimension to scale, defaults to 0.\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "    \"\"\"\n",
    "    x_min, x_max = (\n",
    "        x.min(axis=dim, keepdims=True),\n",
    "        x.max(axis=dim, keepdims=True),\n",
    "    )\n",
    "    x_range = x_max - x_min\n",
    "    x_range = np.where(x_range <= 0.0, eps, x_range)\n",
    "    return (x - x_min) / x_range * (new_range[1] - new_range[0]) + new_range[0]\n",
    "\n",
    "\n",
    "def center_points(xyz: np.ndarray):\n",
    "    \"\"\"\n",
    "    Scale XYZ point cloud coordinates. Sets the min/max Z value to [0, 1] and\n",
    "    min/max XY values to [-1, 1] centered around the mean.\n",
    "    Parameters\n",
    "    ----------\n",
    "    xyz : np.ndarray\n",
    "        Array of shape (N, 3).\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Scaled coordinates.\n",
    "    \"\"\"\n",
    "    centered = center(xyz)\n",
    "    xyz[..., -1] = scale(centered[..., -1], new_range=(0, 1))\n",
    "    xyz[..., :2] = scale(centered[..., :2], new_range=(-1, 1))\n",
    "    return xyz\n",
    "\n",
    "def get_data():\n",
    "    data = {}\n",
    "    for url in DATA_URLS:\n",
    "        partition = url.split(\"/\")[-1].split(\".\")[0]\n",
    "        resp = requests.get(url)\n",
    "        pcl = lp.read(io.BytesIO(resp.content))\n",
    "        xyz = center_points(np.column_stack((pcl.x, pcl.y, pcl.z)))\n",
    "        rgb = np.column_stack((pcl.red, pcl.green, pcl.blue)) / 65280.0\n",
    "        data[partition] = {\n",
    "            \"xyz\": xyz,\n",
    "            \"rgb\": rgb,\n",
    "            \"labels\": pcl.classification,\n",
    "        }\n",
    "    return data\n",
    "\n",
    "def get_data_with_geom():\n",
    "    data = {}\n",
    "    for url in DATA_URLS_WITH_GEOM:\n",
    "        partition = url.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]\n",
    "        resp = requests.get(url)\n",
    "        pcl = lp.read(io.BytesIO(resp.content))\n",
    "        xyz = center_points(np.column_stack((pcl.x, pcl.y, pcl.z)))\n",
    "        rgb = np.column_stack((pcl.red, pcl.green, pcl.blue)) / 65280.0\n",
    "        geom_attrs = []\n",
    "        for extra_dim_name in pcl.point_format.extra_dimension_names:\n",
    "            geom_attrs.append(getattr(pcl, extra_dim_name))\n",
    "        geom_attrs = np.column_stack(geom_attrs)\n",
    "        data[partition] = {\n",
    "            \"xyz\": xyz,\n",
    "            \"rgb\": rgb,\n",
    "            \"labels\": pcl.classification,\n",
    "            \"geom\": geom_attrs\n",
    "        }\n",
    "    return data\n",
    "\n",
    "class TNet(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.k = in_channels\n",
    "        self.mlp1 = nn.Sequential(nn.Conv1d(self.k, 64, 1), nn.ReLU())\n",
    "        self.mlp2 = nn.Sequential(nn.Conv1d(64, 128, 1), nn.ReLU())\n",
    "        self.mlp3 = nn.Sequential(nn.Conv1d(128, 1024, 1), nn.ReLU())\n",
    "        self.mlp4 = nn.Sequential(nn.Conv1d(1024, 512, 1), nn.ReLU())\n",
    "        self.mlp5 = nn.Sequential(nn.Conv1d(512, 256, 1), nn.ReLU())\n",
    "        self.t_mlp = nn.Conv1d(256, self.k**2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.mlp1(x)\n",
    "        x = self.mlp2(x)\n",
    "        x = self.mlp3(x)\n",
    "        x = torch.max(x, -1, keepdims=True)[0]  # B, 1024\n",
    "\n",
    "        x = self.mlp4(x)\n",
    "        x = self.mlp5(x)\n",
    "        x = self.t_mlp(x).reshape(-1, self.k, self.k)  # B, K, K\n",
    "\n",
    "        ident = torch.eye(self.k, device=x.device).unsqueeze(0).repeat(B, 1, 1)\n",
    "        return x + ident\n",
    "\n",
    "class PointNet(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        lr: float = 1e-3,\n",
    "        global_feature: bool=False,\n",
    "        feature_transform: bool=False,\n",
    "        xyz_transform: bool=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._global_feature = global_feature\n",
    "        self._transform_feature = feature_transform\n",
    "        self._transform_xyz = xyz_transform\n",
    "        self.lr = lr\n",
    "\n",
    "        self.xyz_transform = TNet(3) if xyz_transform else nn.Identity()\n",
    "        self.feature_transform = TNet(64) if feature_transform else nn.Identity()\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, 64, 1), nn.BatchNorm1d(64), nn.ReLU()\n",
    "        )\n",
    "        self.mlp2 = nn.Sequential(nn.Conv1d(64, 64, 1), nn.BatchNorm1d(64), nn.ReLU())\n",
    "        self.mlp3 = nn.Sequential(nn.Conv1d(64, 64, 1), nn.BatchNorm1d(64), nn.ReLU())\n",
    "        self.mlp4 = nn.Sequential(nn.Conv1d(64, 128, 1), nn.BatchNorm1d(128), nn.ReLU())\n",
    "        self.mlp5 = nn.Sequential(nn.Conv1d(128, 1024, 1), nn.BatchNorm1d(1024), nn.ReLU())\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv1d(1088, 512, 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(512, 256, 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 128, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Conv1d(128, out_channels, 1),\n",
    "        )\n",
    "\n",
    "        self.scores = []\n",
    "\n",
    "    def forward_base(self, x):\n",
    "        N = x.shape[-1]\n",
    "        if self._transform_xyz:\n",
    "            xyz_trans = self.xyz_transform(x[:, :3])\n",
    "            x[:, :3] = (x[:, :3].mT @ xyz_trans).mT\n",
    "        else:\n",
    "            xyz_trans = None\n",
    "\n",
    "        x = self.mlp1(x)\n",
    "        x = self.mlp2(x)\n",
    "        if self._transform_feature:\n",
    "            feat_trans = self.feature_transform(x)\n",
    "            x = (x.mT @ feat_trans).mT\n",
    "        else:\n",
    "            feat_trans = None\n",
    "\n",
    "        x_local = self.mlp3(x)\n",
    "\n",
    "        x = self.mlp4(x_local)\n",
    "        x = self.mlp5(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x_global = x.max(dim=-1, keepdim=True).values\n",
    "\n",
    "        if self._global_feature:\n",
    "            return x_global.squeeze(-1), xyz_trans, feat_trans\n",
    "\n",
    "        x = torch.cat((x_local, x_global.repeat(1, 1, N)), dim=1)\n",
    "        return x, xyz_trans, feat_trans\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, xyz_trans, feat_trans = self.forward_base(x.mT)\n",
    "        x = self.head(x)\n",
    "        return x.mT, xyz_trans, feat_trans\n",
    "\n",
    "    def _common_step(self, batch, batch_idx, partition):\n",
    "        x, y = batch\n",
    "        logits, _, feat_trans = self.forward(x.float())\n",
    "        if feat_trans is not None:\n",
    "            reg = self._feature_transform_regularizer(feat_trans.mT) * 0.001\n",
    "        else:\n",
    "            reg = 0.0\n",
    "        loss = self.loss_fn(logits.contiguous(), y) + reg\n",
    "        pred = self._activation(logits)\n",
    "        return loss, logits, pred\n",
    "\n",
    "    def _feature_transform_regularizer(self, feat_trans):\n",
    "        D = feat_trans.shape[2]\n",
    "        eye = torch.eye(D, device=self.device)[None, :, :]\n",
    "        loss = torch.norm(eye - (feat_trans @ feat_trans.mT), dim=(1, 2))\n",
    "        return loss.mean()\n",
    "\n",
    "    def _activation(self, y_hat):\n",
    "        probs = torch.sigmoid(y_hat.squeeze(-1))\n",
    "        return torch.where(probs > 0.5, 1, 0)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        loss, logits, pred = self._common_step(train_batch, batch_idx, \"train\")\n",
    "        return {\"loss\": loss, \"logits\": logits, \"pred\": pred}\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        loss, logits, pred = self._common_step(val_batch, batch_idx, \"val\")\n",
    "        self.scores.append(\n",
    "            f1_score(\n",
    "                val_batch[1].flatten().cpu().detach().numpy(),\n",
    "                pred.flatten().cpu().detach().numpy(),\n",
    "                zero_division=0.0,\n",
    "            )\n",
    "        )\n",
    "        return {\"loss\": loss, \"logits\": logits, \"pred\": pred}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "\n",
    "    def on_validation_end(self):\n",
    "        print(f\"F1 Score: {round(sum(self.scores) / len(self.scores), 4)}\")\n",
    "        self.scores = []\n",
    "\n",
    "    def loss_fn(self, y_hat, y):\n",
    "        y_hat = y_hat.squeeze(-1)\n",
    "        return F.binary_cross_entropy_with_logits(\n",
    "            y_hat, y.type(y_hat.dtype)\n",
    "        )\n",
    "\n",
    "class DemoModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        hidden_dims: Sequence[int],\n",
    "        dropout: float = 0.0,\n",
    "        lr: float = 0.001,\n",
    "        kernel_size: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.model = self._init_layers(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            hidden_dims,\n",
    "            kernel_size,\n",
    "            dropout\n",
    "        )\n",
    "        self.scores = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x.mT).mT\n",
    "\n",
    "    def _common_step(self, batch, batch_idx, partition):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x.float())\n",
    "        loss = self.loss_fn(logits.contiguous(), y)\n",
    "        pred = self._activation(logits)\n",
    "        return loss, logits, pred\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        loss, logits, pred = self._common_step(train_batch, batch_idx, \"train\")\n",
    "        return {\"loss\": loss, \"logits\": logits, \"pred\": pred}\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        loss, logits, pred = self._common_step(val_batch, batch_idx, \"val\")\n",
    "        self.scores.append(\n",
    "            f1_score(\n",
    "                val_batch[1].flatten().cpu().detach().numpy(),\n",
    "                pred.flatten().cpu().detach().numpy(),\n",
    "                zero_division=0.0,\n",
    "            )\n",
    "        )\n",
    "        return {\"loss\": loss, \"logits\": logits, \"pred\": pred}\n",
    "\n",
    "    def _activation(self, y_hat):\n",
    "        probs = torch.sigmoid(y_hat.squeeze(-1))\n",
    "        return torch.where(probs > 0.5, 1, 0)\n",
    "\n",
    "    def loss_fn(self, y_hat, y):\n",
    "        y_hat = y_hat.squeeze(-1)\n",
    "        return F.binary_cross_entropy_with_logits(\n",
    "            y_hat, y.type(y_hat.dtype)\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "\n",
    "    def on_validation_end(self):\n",
    "        print(f\"F1 Score: {round(sum(self.scores) / len(self.scores), 4)}\")\n",
    "        self.scores = []\n",
    "\n",
    "    def _init_layers(\n",
    "        self,\n",
    "        input_channels,\n",
    "        output_channels,\n",
    "        hidden_dimensions,\n",
    "        kernel_size,\n",
    "        dropout_prob\n",
    "    ):\n",
    "        layers = []\n",
    "        in_channels = input_channels\n",
    "        num_layers = len(hidden_dimensions)\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            out_channels = hidden_dimensions[i]\n",
    "            layers.append(\n",
    "                nn.Conv1d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding=\"same\",\n",
    "                    bias=False\n",
    "                )\n",
    "            )\n",
    "            layers.append(nn.BatchNorm1d(out_channels))\n",
    "            layers.append(nn.ReLU())\n",
    "            in_channels = out_channels\n",
    "        layers.extend(\n",
    "            [\n",
    "                nn.Dropout(dropout_prob),\n",
    "                nn.Conv1d(\n",
    "                    in_channels,\n",
    "                    output_channels,\n",
    "                    kernel_size=1,\n",
    "                    padding=\"same\"\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "class DemoDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tree: KDTree,\n",
    "        data: dict,\n",
    "        points_per_batch: int=5000,\n",
    "        transform: Callable = lambda x: x,\n",
    "        geometric_features: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.tree = tree\n",
    "        self.data = data\n",
    "        self.points_per_batch = points_per_batch\n",
    "        self.n_points = tree.data.shape[0]\n",
    "        self.transform = transform\n",
    "        self.with_geom = geometric_features\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        query_point = self.tree.data[idx] + np.random.uniform(-.01, .01, 3)\n",
    "        dists, idxs = self.tree.query(query_point, k=self.points_per_batch)\n",
    "        xyz_global = torch.from_numpy(self.data[\"xyz\"][idxs])\n",
    "        xyz_local = torch.from_numpy(center_points(self.data[\"xyz\"][idxs]))\n",
    "        rgb = torch.from_numpy(self.data[\"rgb\"][idxs])\n",
    "        y = torch.from_numpy(self.data[\"labels\"][idxs])\n",
    "        if self.with_geom:\n",
    "            geom = torch.from_numpy(self.data[\"geom\"][idxs])\n",
    "            x = torch.cat((xyz_global, rgb, xyz_local, geom), dim=1)\n",
    "        else:\n",
    "            x = torch.cat((xyz_global, rgb, xyz_local), dim=1)\n",
    "        indexes = torch.randperm(y.shape[0]) # check for permutation invariance\n",
    "        return self.transform(x[indexes]), y[indexes]\n",
    "\n",
    "\n",
    "class DemoDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size: int = 1,\n",
    "        points_per_batch: int = 5000,\n",
    "        transform: Callable = lambda x: x,\n",
    "        geometric_features: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transform\n",
    "        self.points_per_batch = points_per_batch\n",
    "        self.with_geom = geometric_features\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        if self.with_geom:\n",
    "            data = get_data_with_geom()\n",
    "        else:\n",
    "            data = get_data()\n",
    "        train_tree = KDTree(data[\"train\"][\"xyz\"])\n",
    "        val_tree = KDTree(data[\"test\"][\"xyz\"])\n",
    "        self.train_ds = DemoDataset(\n",
    "            train_tree,\n",
    "            data[\"train\"],\n",
    "            points_per_batch=self.points_per_batch,\n",
    "            transform=self.transform,\n",
    "            geometric_features=self.with_geom,\n",
    "        )\n",
    "        self.val_ds = DemoDataset(\n",
    "            val_tree,\n",
    "            data[\"test\"],\n",
    "            points_per_batch=self.points_per_batch,\n",
    "            transform=self.transform,\n",
    "            geometric_features=self.with_geom,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        idxs = np.arange(0, self.train_ds.n_points)\n",
    "        np.random.shuffle(idxs)\n",
    "        n_points = self.train_ds.n_points // self.train_ds.points_per_batch\n",
    "        sampler = SubsetRandomSampler(idxs[:n_points].tolist())\n",
    "        return DataLoader(\n",
    "            self.train_ds, batch_size=self.batch_size, sampler=sampler\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        idxs = np.arange(0, self.val_ds.n_points)\n",
    "        np.random.shuffle(idxs)\n",
    "        n_points = self.val_ds.n_points // self.val_ds.points_per_batch\n",
    "        sampler = SubsetRandomSampler(idxs[:n_points].tolist())\n",
    "        return DataLoader(\n",
    "            self.val_ds, batch_size=self.batch_size, sampler=sampler\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = dict(\n",
    "    hidden_dims=[\n",
    "        64,\n",
    "        128,\n",
    "        256,\n",
    "        512,\n",
    "        1024,\n",
    "        512,\n",
    "        256,\n",
    "        128,\n",
    "    ],\n",
    "    dropout=0.2,\n",
    "    lr=1e-2,\n",
    ")\n",
    "\n",
    "dm_kwargs = dict(\n",
    "    batch_size=1,\n",
    "    points_per_batch=10_000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violate Symmetry\n",
    "1. Train model with `kernel_size=3`\n",
    "2. Train model with `kernel_size=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DemoModel(\n",
    "    in_channels=9,\n",
    "    out_channels=1,\n",
    "    kernel_size=3,\n",
    "    **model_kwargs,\n",
    ")\n",
    "\n",
    "dm = DemoDataModule(\n",
    "    transform=lambda x: x,\n",
    "    geometric_features=False,\n",
    "    **dm_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cal11713\\AppData\\Local\\mambaforge\\envs\\gdl\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:630: Checkpoint directory c:\\Users\\cal11713\\projects\\geometric-deep-learning\\notebooks\\lightning_logs\\version_2\\checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type       | Params\n",
      "-------------------------------------------------\n",
      "0 | xyz_transform     | TNet       | 799 K \n",
      "1 | feature_transform | Identity   | 0     \n",
      "2 | mlp1              | Sequential | 768   \n",
      "3 | mlp2              | Sequential | 4.3 K \n",
      "4 | mlp3              | Sequential | 4.3 K \n",
      "5 | mlp4              | Sequential | 8.6 K \n",
      "6 | mlp5              | Sequential | 134 K \n",
      "7 | dropout           | Dropout    | 0     \n",
      "8 | head              | Sequential | 723 K \n",
      "-------------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n",
      "6.700     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cal11713\\AppData\\Local\\mambaforge\\envs\\gdl\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.6448                                          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cal11713\\AppData\\Local\\mambaforge\\envs\\gdl\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\cal11713\\AppData\\Local\\mambaforge\\envs\\gdl\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:293: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Stability Under Distortion\n",
    "1. Train model with `transform=random_rotate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DemoModel(\n",
    "    in_channels=9,\n",
    "    out_channels=1,\n",
    "    kernel_size=1,\n",
    "    **model_kwargs,\n",
    ")\n",
    "dm = DemoDataModule(\n",
    "    transform=random_rotate,\n",
    "    geometric_features=False,\n",
    "    **dm_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Multiscale Feature Representations\n",
    "1. Train model with `geometric_features=True` and `in_channels=21`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = DemoModel(\n",
    "    in_channels=9 + 12,\n",
    "    out_channels=1,\n",
    "    kernel_size=1,\n",
    "    **model_kwargs,\n",
    ")\n",
    "dm = DemoDataModule(\n",
    "    transform=random_rotate,\n",
    "    geometric_features=True,\n",
    "    **dm_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=model, datamodule=dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
