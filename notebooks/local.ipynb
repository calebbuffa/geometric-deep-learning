{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "from typing import Callable, Sequence\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "import laspy as lp\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URLS = (\n",
    "    \"https://github.com/calebbuffa/geometric-deep-learning/raw/main/data/test.laz\",\n",
    "    \"https://github.com/calebbuffa/geometric-deep-learning/raw/main/data/train.laz\"\n",
    ")\n",
    "\n",
    "DATA_URLS_WITH_GEOM = (\n",
    "    \"https://github.com/calebbuffa/geometric-deep-learning/raw/main/data/test_with_geom.laz\",\n",
    "    \"https://github.com/calebbuffa/geometric-deep-learning/raw/main/data/train_with_geom.laz\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_rotate(x: torch.Tensor):\n",
    "    theta = torch.pi * 2 * torch.rand(1)\n",
    "    rotation_matrix = torch.tensor(\n",
    "        [\n",
    "            [\n",
    "                torch.cos(theta),\n",
    "                -torch.sin(theta)\n",
    "            ],\n",
    "             [\n",
    "                  torch.sin(theta),\n",
    "                  torch.cos(theta)\n",
    "            ]\n",
    "        ],\n",
    "        dtype=x.dtype\n",
    "    )\n",
    "    x[..., [0, 1]] = x[..., [0, 1]] @ (rotation_matrix)\n",
    "    x[..., [6, 7]] = x[..., [6, 7]] @ (rotation_matrix)\n",
    "    return x\n",
    "\n",
    "def center(x: np.ndarray, dim: int = 0):\n",
    "    \"\"\"\n",
    "    Center input to 0 mean.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor\n",
    "        Input to center.\n",
    "    dim : int\n",
    "        Dimension to extract mean, defaults to 0.\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "    \"\"\"\n",
    "    return x - x.mean(axis=dim, keepdims=True)\n",
    "\n",
    "\n",
    "def scale(\n",
    "    x: np.ndarray,\n",
    "    new_range: tuple[int, int] = (-1, 1),\n",
    "    eps: float = 1e-20,\n",
    "    dim: int = 0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Scale input features to new min/max.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor\n",
    "        Features to scale.\n",
    "    new_range : tuple[int, int]\n",
    "        New min/max range, defaults to (-1, 1).\n",
    "    eps : float\n",
    "        Value to avoid division by zero.\n",
    "    dim : int\n",
    "        Dimension to scale, defaults to 0.\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "    \"\"\"\n",
    "    x_min, x_max = (\n",
    "        x.min(axis=dim, keepdims=True),\n",
    "        x.max(axis=dim, keepdims=True),\n",
    "    )\n",
    "    x_range = x_max - x_min\n",
    "    x_range = np.where(x_range <= 0.0, eps, x_range)\n",
    "    return (x - x_min) / x_range * (new_range[1] - new_range[0]) + new_range[0]\n",
    "\n",
    "\n",
    "def center_points(xyz: np.ndarray):\n",
    "    \"\"\"\n",
    "    Scale XYZ point cloud coordinates. Sets the min/max Z value to [0, 1] and\n",
    "    min/max XY values to [-1, 1] centered around the mean.\n",
    "    Parameters\n",
    "    ----------\n",
    "    xyz : np.ndarray\n",
    "        Array of shape (N, 3).\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Scaled coordinates.\n",
    "    \"\"\"\n",
    "    centered = center(xyz)\n",
    "    xyz[..., -1] = scale(centered[..., -1], new_range=(0, 1))\n",
    "    xyz[..., :2] = scale(centered[..., :2], new_range=(-1, 1))\n",
    "    return xyz\n",
    "\n",
    "def get_data():\n",
    "    data = {}\n",
    "    for url in DATA_URLS:\n",
    "        partition = url.split(\"/\")[-1].split(\".\")[0]\n",
    "        resp = requests.get(url)\n",
    "        pcl = lp.read(io.BytesIO(resp.content))\n",
    "        xyz = center_points(np.column_stack((pcl.x, pcl.y, pcl.z)))\n",
    "        rgb = np.column_stack((pcl.red, pcl.green, pcl.blue)) / 65280.0\n",
    "        data[partition] = {\n",
    "            \"xyz\": xyz,\n",
    "            \"rgb\": rgb,\n",
    "            \"labels\": pcl.classification,\n",
    "        }\n",
    "    return data\n",
    "\n",
    "def get_data_with_geom():\n",
    "    data = {}\n",
    "    for url in DATA_URLS_WITH_GEOM:\n",
    "        partition = url.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]\n",
    "        resp = requests.get(url)\n",
    "        pcl = lp.read(io.BytesIO(resp.content))\n",
    "        xyz = center_points(np.column_stack((pcl.x, pcl.y, pcl.z)))\n",
    "        rgb = np.column_stack((pcl.red, pcl.green, pcl.blue)) / 65280.0\n",
    "        geom_attrs = []\n",
    "        for extra_dim_name in pcl.point_format.extra_dimension_names:\n",
    "            geom_attrs.append(getattr(pcl, extra_dim_name))\n",
    "        geom_attrs = np.column_stack(geom_attrs)\n",
    "        data[partition] = {\n",
    "            \"xyz\": xyz,\n",
    "            \"rgb\": rgb,\n",
    "            \"labels\": pcl.classification,\n",
    "            \"geom\": geom_attrs\n",
    "        }\n",
    "    return data\n",
    "\n",
    "class DemoModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        hidden_dims: Sequence[int],\n",
    "        dropout: float = 0.0,\n",
    "        lr: float = 0.001,\n",
    "        kernel_size: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.model = self._init_layers(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            hidden_dims,\n",
    "            kernel_size,\n",
    "            dropout\n",
    "        )\n",
    "        self.scores = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x.mT).mT\n",
    "\n",
    "    def _common_step(self, batch, batch_idx, partition):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x.float())\n",
    "        loss = self.loss_fn(logits.contiguous(), y)\n",
    "        pred = self._activation(logits)\n",
    "        return loss, logits, pred\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        loss, logits, pred = self._common_step(train_batch, batch_idx, \"train\")\n",
    "        return {\"loss\": loss, \"logits\": logits, \"pred\": pred}\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        loss, logits, pred = self._common_step(val_batch, batch_idx, \"val\")\n",
    "        self.scores.append(\n",
    "            f1_score(\n",
    "                val_batch[1].flatten().cpu().detach().numpy(),\n",
    "                pred.flatten().cpu().detach().numpy(),\n",
    "                zero_division=0.0,\n",
    "            )\n",
    "        )\n",
    "        return {\"loss\": loss, \"logits\": logits, \"pred\": pred}\n",
    "\n",
    "    def _activation(self, y_hat):\n",
    "        probs = torch.sigmoid(y_hat.squeeze(-1))\n",
    "        return torch.where(probs > 0.5, 1, 0)\n",
    "\n",
    "    def loss_fn(self, y_hat, y):\n",
    "        y_hat = y_hat.squeeze(-1)\n",
    "        return F.binary_cross_entropy_with_logits(\n",
    "            y_hat, y.type(y_hat.dtype)\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "\n",
    "    def on_validation_end(self):\n",
    "        print(f\"F1 Score: {round(sum(self.scores) / len(self.scores), 4)}\")\n",
    "        self.scores = []\n",
    "\n",
    "    def _init_layers(\n",
    "        self,\n",
    "        input_channels,\n",
    "        output_channels,\n",
    "        hidden_dimensions,\n",
    "        kernel_size,\n",
    "        dropout_prob\n",
    "    ):\n",
    "        layers = []\n",
    "        in_channels = input_channels\n",
    "        num_layers = len(hidden_dimensions)\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            out_channels = hidden_dimensions[i]\n",
    "            layers.append(\n",
    "                nn.Conv1d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding=\"same\",\n",
    "                    bias=False\n",
    "                )\n",
    "            )\n",
    "            layers.append(nn.BatchNorm1d(out_channels))\n",
    "            layers.append(nn.ReLU())\n",
    "            in_channels = out_channels\n",
    "        layers.extend(\n",
    "            [\n",
    "                nn.Dropout(dropout_prob),\n",
    "                nn.Conv1d(\n",
    "                    in_channels,\n",
    "                    output_channels,\n",
    "                    kernel_size=1,\n",
    "                    padding=\"same\"\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "class DemoDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tree: KDTree,\n",
    "        data: dict,\n",
    "        points_per_batch: int=5000,\n",
    "        transform: Callable = lambda x: x,\n",
    "        geometric_features: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.tree = tree\n",
    "        self.data = data\n",
    "        self.points_per_batch = points_per_batch\n",
    "        self.n_points = tree.data.shape[0]\n",
    "        self.transform = transform\n",
    "        self.with_geom = geometric_features\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        query_point = self.tree.data[idx] + np.random.uniform(-.01, .01, 3)\n",
    "        dists, idxs = self.tree.query(query_point, k=self.points_per_batch)\n",
    "        xyz_global = torch.from_numpy(self.data[\"xyz\"][idxs])\n",
    "        xyz_local = torch.from_numpy(center_points(self.data[\"xyz\"][idxs]))\n",
    "        rgb = torch.from_numpy(self.data[\"rgb\"][idxs])\n",
    "        y = torch.from_numpy(self.data[\"labels\"][idxs])\n",
    "        if self.with_geom:\n",
    "            geom = torch.from_numpy(self.data[\"geom\"][idxs])\n",
    "            x = torch.cat((xyz_global, rgb, xyz_local, geom), dim=1)\n",
    "        else:\n",
    "            x = torch.cat((xyz_global, rgb, xyz_local), dim=1)\n",
    "        indexes = torch.randperm(y.shape[0]) # check for permutation invariance\n",
    "        return self.transform(x[indexes]), y[indexes]\n",
    "\n",
    "\n",
    "class DemoDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size: int = 1,\n",
    "        points_per_batch: int = 5000,\n",
    "        transform: Callable = lambda x: x,\n",
    "        geometric_features: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transform\n",
    "        self.points_per_batch = points_per_batch\n",
    "        self.with_geom = geometric_features\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        if self.with_geom:\n",
    "            data = get_data_with_geom()\n",
    "        else:\n",
    "            data = get_data()\n",
    "        train_tree = KDTree(data[\"train\"][\"xyz\"])\n",
    "        val_tree = KDTree(data[\"test\"][\"xyz\"])\n",
    "        self.train_ds = DemoDataset(\n",
    "            train_tree,\n",
    "            data[\"train\"],\n",
    "            points_per_batch=self.points_per_batch,\n",
    "            transform=self.transform,\n",
    "            geometric_features=self.with_geom,\n",
    "        )\n",
    "        self.val_ds = DemoDataset(\n",
    "            val_tree,\n",
    "            data[\"test\"],\n",
    "            points_per_batch=self.points_per_batch,\n",
    "            transform=self.transform,\n",
    "            geometric_features=self.with_geom,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        idxs = np.arange(0, self.train_ds.n_points)\n",
    "        np.random.shuffle(idxs)\n",
    "        n_points = self.train_ds.n_points // self.train_ds.points_per_batch\n",
    "        sampler = SubsetRandomSampler(idxs[:n_points].tolist())\n",
    "        return DataLoader(\n",
    "            self.train_ds, batch_size=self.batch_size, sampler=sampler\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        idxs = np.arange(0, self.val_ds.n_points)\n",
    "        np.random.shuffle(idxs)\n",
    "        n_points = self.val_ds.n_points // self.val_ds.points_per_batch\n",
    "        sampler = SubsetRandomSampler(idxs[:n_points].tolist())\n",
    "        return DataLoader(\n",
    "            self.val_ds, batch_size=self.batch_size, sampler=sampler\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = dict(\n",
    "    hidden_dims=[\n",
    "        64,\n",
    "        128,\n",
    "        256,\n",
    "        512,\n",
    "        1024,\n",
    "        512,\n",
    "        256,\n",
    "        128,\n",
    "    ],\n",
    "    dropout=0.2,\n",
    "    lr=1e-2,\n",
    ")\n",
    "\n",
    "dm_kwargs = dict(\n",
    "    batch_size=1,\n",
    "    points_per_batch=10_000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violate Symmetry\n",
    "1. Train model with `kernel_size=3`\n",
    "2. Train model with `kernel_size=1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = DemoModel(\n",
    "    in_channels=9,\n",
    "    out_channels=1,\n",
    "    kernel_size=3,\n",
    "    **model_kwargs,\n",
    ")\n",
    "dm = DemoDataModule(\n",
    "    transform=lambda x: x,\n",
    "    geometric_features=False,\n",
    "    **dm_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Stability Under Distortion\n",
    "1. Train model with `transform=random_rotate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DemoModel(\n",
    "    in_channels=9,\n",
    "    out_channels=1,\n",
    "    kernel_size=1,\n",
    "    **model_kwargs,\n",
    ")\n",
    "dm = DemoDataModule(\n",
    "    transform=random_rotate,\n",
    "    geometric_features=False,\n",
    "    **dm_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Multiscale Feature Representations\n",
    "1. Train model with `geometric_features=True` and `in_channels=21`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = DemoModel(\n",
    "    in_channels=9 + 12,\n",
    "    out_channels=1,\n",
    "    kernel_size=1,\n",
    "    **model_kwargs,\n",
    ")\n",
    "dm = DemoDataModule(\n",
    "    transform=random_rotate,\n",
    "    geometric_features=True,\n",
    "    **dm_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=model, datamodule=dm)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
